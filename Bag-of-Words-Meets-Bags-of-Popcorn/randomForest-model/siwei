import pandas as pd
from bs4 import BeautifulSoup
import re
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier






def review_to_words(raw_review):
    #1.Remove HTML
    review_text = BeautifulSoup(raw_review,"lxml").get_text()
    #
    #Remove non-letters
    letters_only = re.sub("[^a-zA-Z]]"," ",review_text)
    #
    #converto lower case,split into individual words
    words = letters_only.lower().split()
    #
    #4.convert stop words to set ,because it's faster to search
    stops = set(stopwords.words("english"))
    #
    #5.Remove stop words
    meaningful_words =[w for w in words if w not in stops]
    #
    #6.return string
    return(" ".join(meaningful_words))

def clean_parse_data(data):
    print"Cleaning and parsing the trainning set movie reviews .....\n"
    num_reviews = data["review"].size
    clean_train_reviews = []

    for i in xrange(num_reviews):
        if ((i+1)%1000 == 0):
            print "Review %d of % d \n" % (i+1,num_reviews)
        clean_train_reviews.append(review_to_words(train["review"][i]))
    return clean_train_reviews

def built_bag_of_words(clean_data):
    print "Creating the bag of words....\n"

    #It's possible to use some built-in function here, please look at documents
    vectorizer = CountVectorizer(analyzer="word", \
                             tokenizer=None,      \
                             preprocessor = None, \
                             stop_words = None,   \
                             max_features= 5000)
    train_data_features = vectorizer.fit_transform(clean_data)
    train_data_features = train_data_features.toarray()
    return train_data_features

if __name__ == "__main__":
    #import data and clean parse data
    train = pd.read_csv("labeledTrainData.tsv", header = 0, \
                    delimiter="\t",quoting=3)
    test = pd.read_csv("testData.tsv",header = 0, \
                   delimiter="\t",quoting =3)
    clean_train = clean_parse_data(train)
    clean_test = clean_parse_data(test)
    bag_train = built_bag_of_words(clean_train)
    bag_test = built_bag_of_words(clean_test)

    #build randomforest model
    print("we start building tree------------\n")
    forest = RandomForestClassifier(n_estimators= 100)

    forest = forest.fit(bag_train,train["sentiment"])

    #predict test data using our model
    print("predict result ------------------\n")
    result = forest.predict(bag_test)
    print("produce output ---------------\n")
    output = pd.DataFrame(data={"id":test["id"],"sentiment" : result})

    output.to_csv("Bag_of_Words_model.csv", index = False,quoting = 3)
